{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib\n",
    "import mwparserfromhell\n",
    "import pickle\n",
    "import dateutil\n",
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from io import StringIO, BytesIO\n",
    "import json\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/test3'\n",
    "wiki_title = 'World_War_I'\n",
    "earliest_date=None\n",
    "\n",
    "# process datetime information\n",
    "if earliest_date is not None:\n",
    "    earliest_date = dateutil.parser.DEFAULTPARSER.parse(earliest_date)\n",
    "\n",
    "# Process directory information\n",
    "directory = pathlib.Path(directory)\n",
    "wiklink_directory = directory / 'wikilinks'\n",
    "revision_directory = directory / 'revisions'\n",
    "\n",
    "directory.mkdir(parents=True, exist_ok=True)\n",
    "wiklink_directory.mkdir(parents=True, exist_ok=True)\n",
    "revision_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Consult the database file TODO\n",
    "# This csv will have all pages with timestamps of when they were updated\n",
    "\n",
    "headings = ['page_title', 'revid', 'parentid', 'user', 'userid',\n",
    "            'timestamp', 'comment',\n",
    "            'character_count', 'word_count', 'external_link_count',\n",
    "            'heading_count', 'wikifile_count', 'wikilink_count']\n",
    "# Check the revision history file\n",
    "if (revision_directory / (wiki_title + '.csv')).is_file():\n",
    "    revision_csv = open(revision_directory / (wiki_title + '.csv'), 'a',\n",
    "                        newline='')\n",
    "    revision_writer = csv.writer(revision_csv)\n",
    "else:\n",
    "    revision_csv = open(revision_directory / (wiki_title + '.csv'), 'w',\n",
    "                        newline='')\n",
    "    revision_writer = csv.writer(revision_csv)\n",
    "    revision_writer.writerow(headings)\n",
    "\n",
    "# Check the wikilinks file\n",
    "if (wiklink_directory / (wiki_title + '.json')).is_file():\n",
    "    with open(wiklink_directory / (wiki_title + '.json'), 'r') as tounpick:\n",
    "        wikilink_dict = json.load(tounpick)\n",
    "else:\n",
    "    wikilink_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "earliest_date = '2015-07-01T11:03:28Z'\n",
    "\n",
    "number_of_revisions = 1000\n",
    "\n",
    "\n",
    "url = 'https://en.wikipedia.org/w/index.php?title=Special:Export'\n",
    "data = {'pages': wiki_title,\n",
    "        'limit': '1000',\n",
    "        'offset': str(earliest_date)}\n",
    "\n",
    "print('request_started')\n",
    "r = requests.post(url=url,\n",
    "                  data=data)\n",
    "print('request_complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r =unidecode.unidecode(str(r.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tree = html.parse(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in lxml.etree.iterparse(BytesIO(r.content), tag='revision',html=True):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoup(stringify_children(action[1]), 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = html.parse(BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, action in enumerate(lxml.etree.iterparse(BytesIO(r.content), tag='revision',html=True)):\n",
    "    # revid = parent_id = contrib_username = contrib_id = timestamp = comment = bodytext = None\n",
    "    # for child in action.getchildren():\n",
    "    #     text = child.text\n",
    "    #     tag = child.tag\n",
    "\n",
    "    #     # Big ugly if block to get it done\n",
    "    #     if tag == 'id':\n",
    "    #         revid = text\n",
    "    #     elif tag == 'parentid':\n",
    "    #         parent_id = text\n",
    "    #     elif tag == 'timestamp':\n",
    "    #         timestamp = text\n",
    "    #     elif tag == 'contributor':\n",
    "    #         for child1 in child.getchildren():\n",
    "    #             if child1.tag == 'id':\n",
    "    #                 contrib_id = child1.text\n",
    "    #             elif child1.tag == 'username':\n",
    "    #                 contrib_username = child1.text\n",
    "    #     elif tag == 'comment':\n",
    "    #         comment = text\n",
    "    #     elif tag == 'text':\n",
    "    #         bodytext = text\n",
    "    # if bodytext not None:\n",
    "    #     [character_count, word_count,\n",
    "    #      external_link_count, heading_count,\n",
    "    #      wikilink_count, wikifile_count,\n",
    "    #      wikilink_dict] = parsed_article_metrics(parsed, revid,\n",
    "    #                                          wikilink_dict)\n",
    "    revision = BeautifulSoup(stringify_children(action[1]), 'html5lib')\n",
    "    parsed = mwparserfromhell.parse(revision('text')[0].contents[0])\n",
    "    [revid, parent_id,\n",
    "     contrib_username, contrib_id,\n",
    "     timestamp, comment] = revision_information(revision)\n",
    "    [character_count, word_count,\n",
    "     external_link_count, heading_count,\n",
    "     wikilink_count, wikifile_count,\n",
    "     wikilink_dict] = parsed_article_metrics(parsed, revid,\n",
    "                                             wikilink_dict)\n",
    "    print('here')\n",
    "    try:\n",
    "        print('tried this')\n",
    "        revision_writer.writerow([wiki_title, revid, parent_id,\n",
    "                               contrib_username, contrib_id,\n",
    "                               timestamp, comment, character_count,\n",
    "                               word_count,\n",
    "                               external_link_count, heading_count,\n",
    "                               wikilink_count, wikifile_count])\n",
    "    except UnicodeEncodeError:\n",
    "        print([wiki_title, revid, parent_id,\n",
    "               contrib_username, contrib_id,\n",
    "               timestamp, comment, character_count,\n",
    "               word_count,\n",
    "               external_link_count, heading_count,\n",
    "               wikilink_count, wikifile_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for count, action in enumerate(tree.iter('revision')):\n",
    "    # revid = parent_id = contrib_username = contrib_id = timestamp = comment = bodytext = None\n",
    "    # for child in action.getchildren():\n",
    "    #     text = child.text\n",
    "    #     tag = child.tag\n",
    "\n",
    "    #     # Big ugly if block to get it done\n",
    "    #     if tag == 'id':\n",
    "    #         revid = text\n",
    "    #     elif tag == 'parentid':\n",
    "    #         parent_id = text\n",
    "    #     elif tag == 'timestamp':\n",
    "    #         timestamp = text\n",
    "    #     elif tag == 'contributor':\n",
    "    #         for child1 in child.getchildren():\n",
    "    #             if child1.tag == 'id':\n",
    "    #                 contrib_id = child1.text\n",
    "    #             elif child1.tag == 'username':\n",
    "    #                 contrib_username = child1.text\n",
    "    #     elif tag == 'comment':\n",
    "    #         comment = text\n",
    "    #     elif tag == 'text':\n",
    "    #         bodytext = text\n",
    "    # if bodytext not None:\n",
    "    #     [character_count, word_count,\n",
    "    #      external_link_count, heading_count,\n",
    "    #      wikilink_count, wikifile_count,\n",
    "    #      wikilink_dict] = parsed_article_metrics(parsed, revid,\n",
    "    #                                          wikilink_dict)\n",
    "    revision = BeautifulSoup(stringify_children(action), 'html5lib')\n",
    "    parsed = mwparserfromhell.parse(revision('text')[0].contents[0])\n",
    "    [revid, parent_id,\n",
    "     contrib_username, contrib_id,\n",
    "     timestamp, comment] = revision_information(revision)\n",
    "    [character_count, word_count,\n",
    "     external_link_count, heading_count,\n",
    "     wikilink_count, wikifile_count,\n",
    "     wikilink_dict] = parsed_article_metrics(parsed, revid,\n",
    "                                             wikilink_dict)\n",
    "    print('here')\n",
    "    try:\n",
    "        print('tried this')\n",
    "        revision_writer.writerow([wiki_title, revid, parent_id,\n",
    "                               contrib_username, contrib_id,\n",
    "                               timestamp, comment, character_count,\n",
    "                               word_count,\n",
    "                               external_link_count, heading_count,\n",
    "                               wikilink_count, wikifile_count])\n",
    "    except UnicodeEncodeError:\n",
    "        print([wiki_title, revid, parent_id,\n",
    "               contrib_username, contrib_id,\n",
    "               timestamp, comment, character_count,\n",
    "               word_count,\n",
    "               external_link_count, heading_count,\n",
    "               wikilink_count, wikifile_count])\n",
    "\n",
    "#     earliest_date = timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit revision = BeautifulSoup(stringify_children(action[1]), 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit mwparserfromhell.parse(revision('text')[0].contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit revision_information(revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit parsed_article_metrics(parsed, revid, wikilink_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[wiki_title, revid, parent_id,\n",
    "                               contrib_username, contrib_id,\n",
    "                               timestamp, comment, character_count,\n",
    "                               word_count,\n",
    "                               external_link_count, heading_count,\n",
    "                               wikilink_count, wikifile_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikilink_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_article_metrics(parsed_article, revid, wikilink_dict):\n",
    "    \"\"\"This should take a parsed article and pull out metrics of interest.\n",
    "    Args:\n",
    "        parsed_article (parsed): Parsed wikipedia site (mwparserfromhell)\n",
    "\n",
    "    Returns:\n",
    "        TYPE: list\n",
    "    \"\"\"\n",
    "    character_count = len(parsed_article.strip_code())\n",
    "    # This is not an efficent word count\n",
    "    word_count = len(re.findall(\"[a-zA-Z_]+\", parsed_article.strip_code()))\n",
    "    external_link_count = len(parsed_article.filter_external_links())\n",
    "    heading_count = len(parsed_article.filter_headings())\n",
    "    [wikilink_count, wikifile_count,\n",
    "     wikilink_dict] = process_wikilinks(parsed_article, revid, wikilink_dict)\n",
    "\n",
    "    return [character_count, word_count, external_link_count, heading_count,\n",
    "            wikilink_count, wikifile_count, wikilink_dict]\n",
    "\n",
    "\n",
    "def revision_information(revision_html):\n",
    "\n",
    "    revid = revision_html.id.contents[0]\n",
    "    timestamp = revision_html.timestamp.contents[0]\n",
    "\n",
    "    try:\n",
    "        parent_id = revision_html.parentid.contents[0]\n",
    "    except AttributeError:\n",
    "        # No parent was assigned\n",
    "        parent_id = None\n",
    "\n",
    "    # Contributor\n",
    "    try:\n",
    "        contrib_username = revision_html.contributor.username.contents[0]\n",
    "    except AttributeError:\n",
    "        contrib_username = None\n",
    "\n",
    "    try:\n",
    "        contrib_id = revision_html.contributor.username.id.contents[0]\n",
    "    except AttributeError:\n",
    "        contrib_id = None\n",
    "\n",
    "    try:\n",
    "        comment = revision_html.comment.contents[0]\n",
    "    except AttributeError:\n",
    "        comment = None\n",
    "\n",
    "    return [revid, parent_id,\n",
    "            contrib_username, contrib_id,\n",
    "            timestamp, comment]\n",
    "\n",
    "\n",
    "def process_wikilinks(parsed, revid, wikilink_dictionary):\n",
    "\n",
    "    wikifiles = 0\n",
    "    wikilinks = 0\n",
    "\n",
    "    for link in set([str(link.title) for link in parsed.filter_wikilinks()]):\n",
    "\n",
    "        # Build the dictionary\n",
    "        try:\n",
    "            wikilink_dictionary[link].append(revid)\n",
    "        except KeyError:\n",
    "            wikilink_dictionary[link] = [revid]\n",
    "\n",
    "        if link.startswith('File:'):\n",
    "            wikifiles += 1\n",
    "        else:\n",
    "            wikilinks += 1\n",
    "\n",
    "    return wikilinks, wikifiles, wikilink_dictionary\n",
    "\n",
    "def stringify_children(node):\n",
    "    \"\"\"Given a LXML tag, return contents as a string\n",
    "\n",
    "       >>> html = \"<p><strong>Sample sentence</strong> with tags.</p>\"\n",
    "       >>> node = lxml.html.fragment_fromstring(html)\n",
    "       >>> extract_html_content(node)\n",
    "       \"<strong>Sample sentence</strong> with tags.\"\n",
    "    \"\"\"\n",
    "    if node is None or (len(node) == 0 and not getattr(node, 'text', None)):\n",
    "        return \"\"\n",
    "    node.attrib.clear()\n",
    "    opening_tag = len(node.tag) + 2\n",
    "    closing_tag = -(len(node.tag) + 3)\n",
    "    return html.tostring(node)[opening_tag:closing_tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
